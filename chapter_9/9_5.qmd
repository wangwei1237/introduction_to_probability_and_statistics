## 决定系数和样本相关系数 {#sec-9_5}
::: {.callout-note title="变异量"}
**变异量**（*the amount of variation*）是指一组数据中的变异性，即数据的波动或分散程度。这种波动可以是由多种因素引起的，包括个体差异、测量误差、随机误差等。在后续的翻译章节中，我们会根据具体的场景交叉使用 **变异量** 和 **数据波动**，如无特殊说明，这些指的都是一个概念。

同时，我们会避免使用 **数据差异**（*difference*） 来指代 **变异量** 的概念，因为在数学中，**数据差异** 更多指代两个数据之间的差值，因此和我们所讨论的数据的波动和分布程度并不是一个概念。
:::

针对一组输入值 $x_1, \ldots, x_n$，假设我们想要测量这组输入值对应的响应值（*response value*） $Y_1, \ldots, Y_n$ 之间的数据波动（或 *变异量*）。在统计学中，测量 $Y_1, \ldots, Y_n$ 之间的数据波动（*变异量*）的标准方法为：

$S_{YY} = \sum_{i=1}^{n} (Y_i - \overline{Y})^2$

例如，如果所有的 $Y_i$ 相等，那么 $Y_i$ 都等于 $\overline{Y}$，所以 $S_{YY}$ 将等于 0。

$Y_i$ 之间的波动来源于两个因素。

1. 首先，由于输入值 $x_i$ 是不同的，因此，响应变量 $Y_i$ 具有不同的响应均值，这将导致 $Y_i$ 的值存在一定的波动。
2. 其次，波动还来自这样一个事实：除了输入值 $x_i$ 的差异外，每个响应变量 $Y_i$ 都具有 $\sigma^2$ 的方差。因此，$Y_i$ 不会和$x_i$ 处的预测值完全相等。

让我们考虑这样一个问题：响应值的波动在多大程度上是由不同输入值引起的，又在多大程度上是由响应值的固有方差引起的（已经考虑了输入值的差异）。为了解答这个问题，我们关注到 $SS_R$ 的定义：

$SS_R = \sum_{i=1}^{n} (Y_i - A - Bx_i)^2$

因此，$SS_R$ 度量了响应变量中，除了不同输入值带来的变异量之外的、剩余的变异量。

因此，$S_{YY} - SS_R$ 表示：响应变量中，由不同输入值能够解释的变异量。因此，我们令 $R^2$ 表示为：响应变量中，由不同输入值能够解释的变异量比例。我们称 $R^2$ 为 **决定系数**（*coefficient of determination*），其定义为：

$R^2 = \frac{S_{YY} - SS_R}{S_{YY}} = 1 - \frac{SS_R}{S_{YY}}$

::: {.callout-note title="解释变异量"}
**解释变异量**（*Explained Variation*）是回归分析中的一个重要概念，用于衡量回归模型中自变量能够解释的因变量的变异量。换句话说，解释变异量是由回归模型的预测结果解释的因变量的总变异的一部分。
:::

**决定系数** $R^2$ 的取值范围在 0 和 1 之间。接近 1 的 $R^2$ 表示响应数据的大部分波动性可以由不同的输入值来解释，而接近 0 的 $R^2$ 则表示响应数据的波动几乎不能够由不同的输入值来解释。

::: {#exm-9_5_a}
@exm-9_4_c 中的数据揭示了父子身高之间的关系，我们可以使用 R 计算得到：

```{r}
#| code-fold: false

x <- c(60, 62, 64, 65, 66, 67, 68, 70, 72, 74)
y <- c(63.6, 65.2, 66, 65.5, 66.9, 67.1, 67.4, 68.3, 70.1, 70)
Sxy <- sum(x * y) - 10 * mean(x) * mean(y)
Sxx <- sum(x * x) - 10 * mean(x)^2
Syy <- sum(y * y) - 10 * mean(y)^2
SSr <- (Sxx * Syy - Sxy^2) / Sxx
Syy
SSr

R2 = 1 - SSr / Syy
R2
```

我们可以使用 R 中的 `summary()` 来获取 $R^2$ 的计算结果。

```{r}
#| code-fold: false

x <- c(60, 62, 64, 65, 66, 67, 68, 70, 72, 74)
y <- c(63.6, 65.2, 66, 65.5, 66.9, 67.1, 67.4, 68.3, 70.1, 70)
df <- data.frame(x = x, y = y)
fit <- lm(y ~ x, df)

summary(fit)
```

根据如上结果，我们可以看到：`Multiple R-squared:  0.9612`，`Multiple R-squared` 即 $R^2$。换句话说，在 10 个人的身高波动中，有 96% 的身高波动是由其父亲的身高带来的（解释的），剩下的（未解释的）4% 的数据波动是由于儿子的身高波动带来的（即随机误差的方差  $\sigma^2$）。$\blacksquare$
:::

通用用 **决定系数** $R^2$ 的值作为回归模型对数据拟合好坏的指标，$R^2$ 值越接近 1 则表示拟合效果越好，而 $R^2$ 值越接近 0 则表示拟合效果越差。换句话说，如果回归模型能够解释响应数据中的绝大部分波动（*variation in the response data*），那么就认为该模型可以较好的拟合数据。

回想一下我们在 @sec-2_6 中定义的数据对 $(x_i, Y_i), i = 1, \ldots, n$ 的 **样本相关系数**  $r$：

$r = \frac{\sum_{i=1}^{n} (x_i - \overline{x})(Y_i - \overline{Y})}{\sqrt{\sum_{i=1}^{n} (x_i - \overline{x})^2 \sum_{i=1}^{n} (Y_i - \overline{Y})^2}}$

 **样本相关系数**  $r$ 提供了一种衡量 $x$ 和 $Y$ 之间相关性强度的方式。当 $r$ 接近 +1 时，表示较大的 $x$ 对应着较大的 $Y$，并且较小的 $x$ 对应着较小的 $Y$；当 $r$ 接近 -1 时，表示较大的 $x$ 对应着较小的 $Y$，并且较小的 $x$ 对应着较大的 $Y$。

在本章中，$r = \frac{S_{xY}}{\sqrt{S_{xx} S_{YY}}}$，根据 @eq-9_3_4 有：$SS_R = \frac{S_{xx}S_{YY} - S_{xY}^2}{S_{xx}}$，于是有：

$\begin{align}r^2 &= \frac{S_{xY}^2}{S_{xx} S_{YY}} \\ &= \frac{S_{xx}S_{YY} - SS_R S_{xx}}{S_{xx}S_{YY}} \\ &= 1 - \frac{SS_R}{S_{YY}} \\ &= R^2\end{align}$

即：

$|r| = \sqrt{R^2}$

因此，除了 $r$ 的符号表示它是正相关还是负相关外，**样本相关系数** 和 **决定系数** 的平方根是一致的。$r$ 的符号与参数 $B$ 的符号相同。

如上的内容为 **样本相关系数** 提供了额外的意义。例如，如果一个数据集的 **样本相关系数**  $r$ 等于 0.9，那么这意味着对于这些数据的 **简单线性回归模型** 可以解释 **响应变量** 81% 的数据波动（*variation*）（因为 $R^2 = 0.9^2 = 0.81$）。换句话说，对于响应变量的数据波动而言，81% 可以由不同的输入值来解释。