## 二项分布的假设检验
二项分布在工程问题中经常遇到。例如，考虑一种产品生产线，该生产线制造的产品可以分为两类——可接受的或有缺陷的。通常会假设生产的每个产品的缺陷概率为 $p$，因此一个具有 $n$ 个产品的样本中的缺陷产品数量将是参数为 $(n, p)$ 的二项分布。现在考虑以下的假设检验：

$H_0 : p \le p_0 \quad versus \quad H_1 : p > p_0$

其中 $p_0$ 是某个指定的值。

如果令 $X$ 表示样本大小为 $n$ 的样本中的缺陷数，那么显然当 $X$ 较大时我们希望拒绝 $H_0$。为了计算在显著性水平 $\alpha$ 下需要多大的 $X$ 才能证明拒绝是合理的，我们关注到：

$P\{X \ge k\} = \sum_{i=k}^{n} P\{X = i\} = \sum_{i=k}^{n} \binom{n}{i} p^i (1 - p)^{n-i}$

现在，很直观（并且可以证明），$P\{X \ge k\}$ 是 $p$ 的递增函数——即，样本中包含至少 $k$ 个缺陷产品的概率随着缺陷概率 $p$ 的增加而增加。使用这一点，我们看到当 $H_0$ 为真时（即 $p \le p_0$），

$P\{X \ge k\} \le \sum_{i=k}^{n} \binom{n}{i} p_0^i (1 - p_0)^{n-i}$

因此，显著性水平 $\alpha$ 下的假设检验

$H_0 : p \le p_0$ $versus$ $H_1 : p > p_0$ 

是当 $X \ge k^*$ 时拒绝 $H_0$，其中 $k^*$ 是使 $\sum_{i=k}^{n} \binom{n}{i} p_0^i (1 - p_0)^{n-i} \le \alpha$ 成立的最小的 $k$ 值。也就是说，

$k^* = \min \left\{ k : \sum_{i=k}^{n} \binom{n}{i} p_0^i (1 - p_0)^{n-i} \le \alpha \right\}$

可以通过首先确定检验统计量的值——例如 $X = x$，然后再计算给定的 $p$-值 来执行假设检验。

$$
\begin{align}
p-\text{value} &= P\{B(n, p_0) \ge x\} \\
&= \sum_{i=x}^{n}{\left(\begin{array}{cc}  n \\ i  \end{array}\right)p_0^i(1-p_0)^{n-i}}
\end{align}
$$

::: {#exr-8_6_a}
一家电脑芯片制造商声称他们出售的芯片的缺陷率不超过 2%。一家电子公司对这家芯片公司的声明印象深刻，并购买了该芯片公司生产的大量芯片。为了确定芯片制造商的声明的可信性，该电子公司决定测试 300 个芯片样本。如果最终发现这 300 个芯片中有 10 个是有缺陷的，那么是否应该拒绝芯片制造商的声明？
:::

::: {#sol-8_6_a}
让我们在 5% 的显著性水平上检测制造商的声明。为了判断是否需要拒绝制造商 2% 缺陷率的声明，我们需要计算当 $p$ 等于 0.02 时，300 个样本中出现 10 个或更多个缺陷产品的概率。也就是说，我们需要计算 $p-\text{value}$。如果 $p-\text{value}$ 小于或等于 0.05，那么就应该拒绝制造商 2% 缺陷率的声明。

$$
\begin{align}
P_{0.02}\{X \ge 10\} &= 1 - P_{0.02}\{X \le 9\} \\
&= 1 - pbinom(9, 300, 0.02) \\
&= 0.08183807
\end{align}
$$

因此，在显著性水平为 0.05 时，我们不能拒绝芯片制造商的声明。

::: {.callout-note}
当然，在 R 中，我们可以使用 `binom.test()` 来直接根据实验结果计算二项分布的 $p-\text{value}$。

```{r}
binom.test(10, 300, 0.02, "greater")
```
:::

$\blacksquare$
:::

### 检验两个伯努利总体的参数是否相同 {#sec-8_6_1}
假设某类型的芯片有两种不同的生产方法，并且假设第一种生产方法生产的芯片的缺陷率为 $p_1$，而第二种生产方法生产的芯片的缺陷率为 $p_2$。为了检验假设 $p_1 = p_2$，我们使用第一种方法生产了 $n_1$ 个芯片作为样本 1，使用第二种方法生产了 $n_2$ 个芯片作为样本 2。

令 $X_1$ 表示样本 1 中的缺陷芯片的数量，$X_2$  表示样本 2 中的缺陷芯片的数量。因此，$X_1$ 和 $X_2$ 是相互独立的二项分布随机变量，其参数分别为 $(n_1, p_1)$ 和 $(n_2, p_2)$。假设 $X_1 + X_2 = k$，那么两个样本总共有 $k$ 个缺陷品。

如果 $H_0$（$p_1 = p_2$）成立，那么 $n_1 + n_2$ 个芯片中的每一个都有相同的概率成为缺陷品。因此 $k$ 个缺陷品的分布与从一个包含  $n_1 + n_2$ 个物品（其中 $n_1$ 是白色物品， $n_2$ 是黑色物品）中随机抽取 $k$ 个样本的分布相同。换句话说，给定总共 $k$ 个缺陷品，当 $H_0$ 成立时，使用第一种方法得到的缺陷品数量的条件分布将具有以下的超几何分布：

$$
P_{H_0}\{X_1 = i | X_1 + X_2 = k\} = \frac{\binom{n_1}{i}\binom{n_2}{k-i}}{\binom{n_1+n_2}{k}}, \quad i = 0, 1, \ldots, k
$$ {#eq-8_6_1}

在检验 $H_0: p_1 = p_2 \quad vs \quad H_1: p_1 \neq p_2$ 时，当使用第一种方法生产的缺陷芯片比例与使用第二种方法生产的缺陷芯片比例差异很大时，似乎可以合理地拒绝原假设。因此，如果总共存在 $k$ 个缺陷品，那么当 $H_0$ 成立时，我们预计 $X_1/n_1$（使用第一种方法生产的缺陷芯片比例）将接近于 $(k - X_1)/n_2$ （使用第二种方法生产的缺陷芯片比例）。当 $X_1$ 非常小或非常大时，$X_1/n_1$ 和 $(k - X_1)/n_2$ 之间的差异会比较大，因此，合理的显著性水平 $\alpha$ 的检验如下所示。

当 $X_1 + X_2 = k$ 时，

$$
\begin{align}
\text{拒绝} H_0 &, \quad \text{如果} P\{X \leq x_1\} \leq \alpha/2 \quad \text{ 或 } \quad P\{X \geq x_1\} \leq \alpha/2 \\
\text{接受} H_0 &, \quad 否则
\end{align}
$$

其中 $X$ 是具有以下概率质量函数的超几何随机变量：

$$
P\{X = i\} = \frac{\binom{n_1}{i}\binom{n_2}{k-i}}{\binom{n_1+n_2}{k}}, \quad i = 0, 1, \ldots, k
$$ {#eq-8_6_2}

$$
p-\text{value} = 2 \min(P\{X \leq x_1\}, P\{X \geq x_1\})
$$ {#eq-8_6_3}

换句话说，如果显著性水平至少为 $\alpha$ 大于等于 $p-\text{value}$，我们将拒绝原假设。这种检验也称之为 Fisher-Irwin 检验。

可以通过使用 R 命令 `phyper(x, n, m, k)` 来计算 @eq-8_6_3 的概率，该命令用于计算超几何随机变量的概率，其参数 $n, m, k$ 代表从一个包含 $n$ 个红球和 $m$ 个蓝球的盒子中随机抽取 $k$ 个球时，抽取的红球数量小于或等于 $x$ 的概率。