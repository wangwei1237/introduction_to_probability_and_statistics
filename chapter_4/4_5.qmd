## 期望的特征 {#sec-4_5}
假设我们给定一个 **随机变量** $X$ 和其 **概率分布**。又假设，我们对计算 $X$ 的 **期望** 不感兴趣，而对计算关于 $X$ 的某个函数 $g(X)$ 的 **期望** 感兴趣。如何计算 $g(X)$ 的 **期望**？如下就是一种计算方法。由于 $g(X)$ 本身是一个 **随机变量**，因此 $g(X)$ 必存在一个概率分布，并且这个概率分布可以通过 $X$ 的概率分布来计算。一旦我们得到了 $g(X)$ 的分布，我们就可以通过期望的定义来计算 $E[g(X)]$。

::: {.callout-tip title="概率分布"}
概率分布即——离散 **随机变量** 的 *概率质量函数* 或连续 **随机变量** 的 *概率密度函数*。
:::

::: {#exr-4_5_a}
假设 $X$ 的概率质量函数函数为：$p(0)=0.2$，$p(1)=0.5$，$p(2)=0.3$，计算 $E[X^2]$。
:::

::: {#sol-4_5_a}
令 $Y=X^2$，则 $Y$ 是一个取值为 $0^2$，$1^2$，$2^2$ 的 **随机变量**，并且其可能取值的概率分别为：

$p_Y(0) = P\{Y = 0^2\} = 0.2$

$p_Y(1) = P\{Y = 1^2\} = 0.5$

$p_Y(2) = P\{Y = 2^2\} = 0.3$

因此，$E[X^2] = E[Y] = 0 \cdot 0.2 + 1 \cdot 0.5 + 4 \cdot 0.3 = 1.7$。$\blacksquare$
:::

::: {#exr-4_5_b}
定位并修复某工厂的电气故障所需的时间（以小时为单位）是一个 **随机变量** $X$，其概率密度函数为：

$$
f_X(x) = \begin{cases}
1, \quad & 0 \lt x \lt 1 \\
0, \quad & otherwise
\end{cases}
$$

如果对修复时间 $x$ 的细分成本是 $x^3$，那么这种细分的期望成本是多少？
:::

::: {#sol-4_5_b}
令 $Y = X^3$，我们首先计算 $Y$ 的分布函数：

$$
\begin{align}
F_Y(a) &= P\{Y \le a\} \\
&= P\{X^3 \le a\} \\
&= P\{X \le a^{\frac{1}{3}}\} \\
&= \int_{0}^{a^{\frac{1}{3}}}{1  \mathrm{d} x} \\
&= a^{\frac{1}{3}} \\
其中，& 0 \le a \le 1
\end{align}
$$

对 $F_Y(a)$ 求导得到概率密度函数 $f_Y(a)=\frac{1}{3}a^{-\frac{2}{3}},\ 0 \le a \le 1$。因此：

$$
\begin{align}
E[X^3] &= E[Y] = \int_{-\infty}^{\infty}{a \cdot f_Y(a) da} \\
&= \int_{0}^{1}{a \cdot a^{-\frac{2}{3}} da} \\
&= \frac{1}{3} \int_{0}^{1}{a^{\frac{1}{3}}da} \\
&= (\frac{1}{3} \cdot \frac{3}{4} \cdot a^{\frac{4}{3}}) \big |_{0}^{1} \\
&= \frac{1}{4} \quad \blacksquare
\end{align}
$$
:::

虽然上述过程允许我们可以在理论上利用 $X$ 的分布来计算 $X$ 的任何函数的 **期望**，但我们还有一种更简单的方法。例如，假设我们想计算 $g(X)$ 的 **期望**。当 $X=x$ 时，$g(X)$ 的取值为 $g(x)，因此 $E[g(X)]$ 应该是 $g(X)$ 的加权平均数，其中 $g(x)$ 的权重就是 $X=x$ 的概率（或概率密度）。事实上，我们可以证明上述过程是正确的，因此我们有以下的命题。

::: {#prp-4_5_1}
一个 **随机变量** 的函数的 **期望**：

* 如果一个离散 **随机变量** $X$ 的概率质量函数为 $p(x)$，则对于任一函数 $g$，$E[g(X)] = \sum_{x}{g(x)p(x)}$。
* 如果一个连续 **随机变量** $X$ 的概率密度函数为 $f(x)$，则对于任一函数 $g$，$E[g(X)] = \int_{-\infty}^{\infty}{g(x)f(x) \mathrm{d} x}$。
:::

::: {#exm-4_5_c}
利用 @prp-4_5_1 来计算 @exr-4_5_a 有：

$E[X^2] = 0^2 \cdot 0.2 + 1^2 \cdot 0.5 + 2^2 \cdot 0.3 = 1.7$。$\blacksquare$
:::

::: {#exm-4_5_d}
利用 @prp-4_5_1 来计算 @exr-4_5_b 有：

$E[X^3] = \int_{0}^{1}{x^3} \mathrm{d} x = \frac{1}{4}$。 $\blacksquare$
:::

根据 @prp-4_5_1，我们有 @cor-4_5_2。

::: {#cor-4_5_2}
如果 $a$ 和 $b$ 是常数，则 $E[aX + b] = aE[X] + b$。
:::

::: {.proof}
* 对于离散随机变量：
  $$
  \begin{align}
  E[aX + b] &= \sum_{x}{(ax + b)p(x)} \\
  &= a\sum_{x}{xp(x)} + b\sum_{x}{p(x)} \\
  &= aE[X] + b
  \end{align}
  $$
* 对于连续随机变量：
  $$
  \begin{align}
  E[aX + b] &= \int_{-\infty}^{\infty}{(ax + b)f(x) \mathrm{d} x} \\
  &= a\int_{-\infty}^{\infty}{xf(x) \mathrm{d} x} + b\int_{-\infty}^{\infty}{f(x) \mathrm{d} x} \\
  &= aE[X] + b \quad \blacksquare
  \end{align}
  $$
:::

如果令 $a=0$，则根据 @cor-4_5_2 有：$E[b] = b$。也就是说，常量的 **期望** 就是它本身。（这符合你的直觉吗？）另外，如果我们令 $b=0$，那么我们得到 $E[aX] = aE[X]$。

换句话说，常数乘以 **随机变量** 的 **期望** 就是该常数乘以这个 **随机变量** 的期望。随机变量 $X$ 的 **期望** $E[X]$ 也称为 $X$ 的平均值或一阶矩（*the first moment*）。当 $n \ge 1$ 时，$E[X^n]$ 称为 $X$ 的 $n$-阶矩。根据 @prp-4_5_1，我们有：

$$
E[X^n] = \begin{cases}
\sum_{x}{x^np(x)}, \quad & X 为离散随机变量\\
& \\
& \\
\int_{-\infty}^{\infty}{x^nf(x) \mathrm{d} x}, \quad & X 为连续随机变量
\end{cases}
$$

### 随机变量和的期望
对于 @prp-4_5_1 而言，如果有两个 **随机变量** $X$、$Y$，并且 $g$ 为关于 $X$、$Y$ 的函数，那么有：

$$
E[g(X,Y)] = \begin{cases}
\sum_{y} \sum_{x} g(x,y)p(x,y), \quad & 离散随机变量\\
& \\
& \\
\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g(x,y)f(x,y) \mathrm{d} x \mathrm{d} y, \quad & 连续随机变量
\end{cases}
$$

例如，如果 $g(X,Y)=X+Y$ 且 $X$、$Y$ 为连续 **随机变量**，则：

$$
\begin{align}
E[X+Y] &= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(x+y)f(x,y) \mathrm{d} x \mathrm{d} y \\
&= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}xf(x,y) \mathrm{d} x \mathrm{d} y + \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}yf(x,y) \mathrm{d} x \mathrm{d} y \\
&= E[X] + E[Y]
\end{align}
$$

类似的，对于离散随机变量而言，也有：

$$
E[X+Y]=E[X] + E[Y]
$$ {#eq-4_5_001_451}

重复应用 @eq-4_5_001_451，我们可以证明：任意数量的 **随机变量** 之和的 **期望** 等于它们各自 **期望** 的和。例如，

$$
\begin{align}
E[X+Y+Z] &= E[(X+Y)+Z] \\
&= E[X+Y] + E[Z]  \\
&= E[X] + E[Y] + E[Z]  
\end{align}
$$

更一般的，对于任意的 $n$，

$$
E[X_1 + X_2 + ... + X_n] = E[X_1] + E[X_2] + ... + E[X_n]
$$ {#eq-4_5_002_452}

@eq-4_5_002_452 是一个非常有用的公式，接下来，我们将通过一系列的例子来说明其作用。

::: {#exr-4_5_e}
抛两个骰子，计算两个骰子的和的期望值。
:::

::: {#sol-4_5_e}
如果令 $X$ 是两个骰子的和，则

$E[X]=\sum_{i=2}^{12}{iP\{X=i\}}$

我们令 $X_1$、$X_2$ 分别表示这两个骰子的点数，则有 $X = X_1 + X_2$，于是有：

$E[X] = E[X_1 + X_2] = E[X_1] + E[X_2]$，根据 @eq-4_5_002_452 有 $E[X] = 7$。$\blacksquare$
:::

::: {#exr-4_5_f}
一家建筑公司最近投标了三个项目，这三个项目可以获得的利润分别为 1 万美元、2 万美元、4 万美元。对这三个项目，如果该公司中标的概率分别为 0.2、0.8、0.3，那么该公司的预期总利润是多少？
:::

::: {#sol-4_5_f}
令 $X_i$ 表示投标的第 $i$ 个项目的利润，其中 $i=1,2,3$。令 $X$ 表示总利润，则 $X = X_1 + X_2 + X_3$。所以，

$E[X] = E[X_1 + X_2 + X_3] = E[X_1] + E[X_2] + E[X_3] = 3 万美元$。$\blacksquare$
:::

::: {#exr-4_5_g}
秘书打印出了 $N$ 封信件以及信件对应的信封。当信封掉在地板上时，他们会混在一起。如果这 $N$ 封信件以完全随机的方式放在已经混淆的信封里（每封信件放在任何一个信封的概率相同），则放到正确的信封中的信件数量的期望值是多少？
:::

::: {#sol-4_5_g}
令 $X$ 表示放到正确的信封中的信件数量，则：

$X = X_1 + X_2 + ... + X_N$，其中 $X_i = \begin{cases} 1, \quad & 第 i 封信放在了第 i 个信封中\\ 0, \quad & 其他 \end{cases}$。

由于第 $i$ 封信放入 $N$ 个信封中的可能性是相同的，因此，$P\{X_i=1\}=\frac{1}{N}$。

所以有：$E[X_i]=1 \cdot P\{X_i = 1\} + 0 \cdot P\{X_i = 0\} = \frac{1}{N}$，根据 @eq-4_5_002_452 有：

$E[X] = E[X_1] + ... + E[X_N] = \frac{1}{N} N =1$。 

因此，不管有多少封信，平均来说，只有一封信会放在正确的信封里。$\blacksquare$
:::

::: {#exr-4_5_h}
假设有 20 种不同类型的优惠券，并且每次获取优惠券时得到每一种优惠券的可能性都是相等的。如果现在获得了 10 张优惠券，计算其中包含的优惠券种类的预期数量。
:::

::: {#sol-4_5_h}
令 $X$ 表示这 10 张优惠券中包含的优惠券类型的数量，则：

$X = X_1 + ... + X_20$，其中 $X_i = \begin{cases} 1, \quad & 至少有 1 张第 i 种优惠券\\ 0, \quad & 其他 \end{cases}$。

所以有：

$$
\begin{align}
E[X_i] &= P\{X_i = 1\} \\
&= P\{在 10 张优惠券中至少有 1 张第 i 种优惠券\} \\
&= 1 - P\{在 10 张优惠券中不存在第 i 种优惠券\} \\
&= 1 - \bigg(\frac{19}{20}\bigg)^{10}
\end{align}
$$

所以 $E[X] = E[X_1] + ... + E[X_20] = 20 \cdot \Bigg(1 - \big(\frac{19}{20}\big)^{10}\Bigg) = 8.025$。$\blacksquare$
:::

当我们必须预测一个 **随机变量** 的值时，均值（*mean*）的一个重要属性就显现出来了。也就是说，假设要预测一个 **随机变量** $X$ 的值，如果我们预测 $X$ 将等于 $c$，那么预测“误差”（或者称为：残差）的平方将是 $(X−c)^2$。接下来，我们将证明：当 $X$ 的预测值等于它的均值 $\mu$ 时，均方误差的值是最小的。

对于任何常数 $c$ 有：

$$
\begin{align}
E[(X-c)^2] &= E[(X - \mu + \mu - c)^2] \\
&= E[(X - \mu)^2 + 2(X - \mu)(\mu - c) + (\mu -c)^2] \\
&= E[(X - \mu)^2] + 2(\mu - c)E[(X - \mu)] + (\mu -c)^2 \\
&= E[(X - \mu)^2] + (\mu -c)^2, \qquad \because E[X - \mu] = E[X] - \mu = 0 \\
&\ge E[(X - \mu)^2]
\end{align}
$$

因此，当 **随机变量** 的平方误差的期望最小时，可以得到 **随机变量** 的最佳预测器——即其平均值。