## 最大似然估计 {#sec-7_2}
任何用于估计未知参数 $\theta$ 的值的统计量都称为 $\theta$ 的 **估计量**（*estimator*）。估计量的观测值称为 **估计值**（*estimate*）。例如，一般而言，对于正态分布的均值的估计量是基于样本 $X_1, ..., X_n$ 的样本均值 $\overline{X} = \frac{\sum_i{X_i}}{n}$。如果样本的大小为 3，并且样本数据为 $X_1=2$，$X_2=3$，$X_3=4$，那么根据估计量 $\overline{X}$ 则得到总体均值的估计值 3。

假设随机变量 $X_1, \ldots, X_n$ 的联合分布是已知的，只是有一个未知参数 $\theta$。我们关注的问题是使用观察到的值来估计 $\theta$。例如， $X_i$ 可能是独立的指数随机变量，每个变量具有相同的未知均值 $\theta$。在这种情况下，随机变量的联合密度函数将由以下公式给出：

假设随机变量 $X_1, ..., X_n$ 的联合分布是已知的，只是有一个未知的参数 $\theta$。我们关注的问题是：使用观察到的数据来估计 $\theta$。例如，$X_i$ 可能是相互独立的指数随机变量，每个变量都具有相同的未知均值 $\theta$。在这种情况下，随机变量的联合密度函数为：

$$
\begin{align}
f(x_1, x_2, ..., x_n) &= f_{X_1}(x_1) f_{X_2}(x_2) \cdots f_{X_n}(x_n) \\
&= \frac{1}{\theta}e^{-\frac{x_1}{\theta}} \frac{1}{\theta}e^{-\frac{x_2}{\theta}} \cdots \frac{1}{\theta}e^{-\frac{x_n}{\theta}} \\
&= \frac{1}{\theta^n}e^{-{\frac{\sum_{i=1}^{n}{x_i}}{\theta}}}
\end{align}
$$

我们的目标就是根据观测数据 $x_1, x_2, ..., x_n$ 来估计 $\theta$。

在统计学中，一种被广泛使用的、特殊类型的估计量就是最大似然估计量（*maximum likelihood estimator*）。最大似然估计的推导过程如下。

1. 令 $f(x_1, ..., x_n | \theta)$ 表示随机变量 $X_1, X_2, ..., X_n$ 的联合概率质量函数（当它们是离散随机变量时）或者联合概率密度函数（当它们是连续随机变量时）。因为我们假定 $\theta$ 未知，所以我们也将 $f$ 写成 $\theta$ 的函数。
2. 现在，$f(x_1, ..., x_n | \theta)$ 表示当参数 $\theta$ 是其真实值时，观测值为 $x_1, x_2, ..., x_n$ 的可能性（*likelihood*）。因此，$\theta$ 的合理的估计值应该是使得观测值的可能性最大的那个 $\theta$ 值。
3. 换句话说，最大似然估计 $\hat{\theta}$ 就是令 $f(x_1, ..., x_n | \theta)$ 取得最大值的 $\theta$ 值，其中 $x_1, ..., x_n$ 表示观侧数据。而函数 $f(x_1, ..., x_n | \theta)$ 也被称为关于 $\theta$ 的似然函数。
4. 为了确定 $f(x_1, ..., x_n | \theta)$ 最大时的 $\theta$ 值，通常会利用以下的事实：函数 $f(x_1, ..., x_n | \theta)$ 和函数 $\textup{log}[f(x_1, ..., x_n | \theta)]$ 取得最大值时的 $\theta$ 值是相同的。因此，我们也可以通过最大化 $\textup{log}[f(x_1, ..., x_n | \theta)]$ 得到 $\hat{\theta}$。

::: {#exr-7_2_a}
**伯努利分布参数的最大似然估计**。假设执行 $n$ 个独立试验，每个试验的成功概率均为 $p$。则 $p$ 的最大似然估计是多少？
:::

::: {#sol-7_2_a}
观察数据由 $X_1, ..., X_n$ 的值构成，其中 $X_i = \begin{cases} 1, \quad & 第 i 次试验成功\\ 0, \quad & 其它 \end{cases}$

令 $P\{X_i = 1\} = p = 1- P\{X_i = 0\}$，该等式可以简化为：

$P\{X_i = x\} = p^x(1-p)^{1-x}, \quad x = 0,1$

因此试验之间相互独立，因此观察到的数据的可能性（*likelihook*，指的就是联合概率质量函数）为：

$\begin{align} f(x_1, ..., x_n | p) &= P\{X_1 = x_1, ..., X_n = x_n | p\} \\ &= p^{x_1}(1-p)^{1-x_1} \cdots p^{x_n}(1-p)^{1-x_n} \\ &= p^{\sum_{i=1}^{n}{x_i}} (1-p)^{n - \sum_{i=1}^{n}{x_i}}, \quad x_i = 0,1, \quad i = 1,...,n \end{align}$

为了确定是的 $f$ 取得最大值时 $p$ 的值，首先对 $f$ 取对数：
$\textup{log}f(x_1, ..., x_n | p) = \bigg(\sum_{i=1}^{n}{x_i}\bigg)\textup{log}\ p +\bigg (n - \sum_{i=1}^{n}{x_i}\bigg)\textup{log}(1 - p)$

求导得到：

$\frac{d}{dp} \textup{log}\ f(x_1, ..., x_n | p) = \frac{\sum_{i=1}^{n}{x_i}}{p} -\frac{n - \sum_{i=1}^{n}{x_i}}{1-p}$

令 $\frac{d}{dp} \textup{log}\ f(x_1, ..., x_n | p) = 0$ 并计算得到最大似然估计 $\hat{p}$ 满足：

$\frac{\sum_{i=1}^{n}{x_i}}{\hat{p}} -\frac{n - \sum_{i=1}^{n}{x_i}}{1-\hat{p}}$

即，$\hat{p} = \frac{\sum_{i=1}^{n}{x_i}}{n}$

因此，均值未知的伯努利分布的最大似然估计量为：

$d(X_1, ..., X_n) = \frac{\sum_{i=1}^{n}{X_i}}{n}$

因为 $\sum_{i=1}^{n}{X_i}$ 就是试验成功的次数，所以 $p$ 的最大似然估计就等于观察到的实验中成功次数的占比。举个例子，假设某制造商生产的 每个 RAM（运行内存）芯片的合格率是相互独立的，并且合格率为 $p$。如果在 1000 个测试样本中，有 921 个合格品，那么 $p$ 的最大似然估计是 0.921。 $\blacksquare$
:::

::: {#exr-7_2_b}
两位编辑审验相同的一本稿件，如果第一位编辑发现 $n_1$ 个错误，第二位编辑发现 $n_2$ 个错误，其中有 $n_{1,2}$ 个错误两位编辑都发现了，估计这本稿件中的错误总数 $N$。
:::

::: {#sol-7_2_b}
在估计 $N$ 之前，需要对潜在的概率模型做一些假设。假设不同编辑的审验结果之间是独立的，并且稿件中的每个错误被第 $i$ 位编辑独立发现的概率为 $p_i,\ i = 1,2$。

为了估计 $N$，我们将从推导 $p_1$ 的估计量开始。为此，请注意，第一位编辑将会以 $p_1$ 的概率独立发现第二位编辑发现的 $n_2$ 个错误中的每一个错误。因为第一位编辑发现了$n_2$ 个错误中的 $n_{1,2}$ 个错误，因此，$p_1$ 的合理估计为：

$\hat{p}_1 = \frac{n_{1,2}}{n_2}$

但是，对于稿件中的 $N$ 个错误，因为第一位编辑发现了其中的 $n_1$ 个错误，因此假设 $p_1$ 近似的等于 $\frac{n_1}{N}$ 也是合理的。因此 $\hat{p}_1 \approx \frac{n_1}{N}$，即 $\frac{n_{1,2}}{n_2}\approx \frac{n_1}{N}$，也就是说：

$N \approx \frac{n_1 n_2}{n_{1,2}}$

因为如上的估计对于 $n_1$ 和 $n_2$ 是对称的，所以无论哪个编辑是第一位编辑，最终的结果都是相同的。

当两个研究小组宣布他们已经破译了人类遗传密码序列时，如上估计过程的一个有趣的案例发生了。作为两个研究小组工作的一部分，他们都估计人类基因组由大约 33000 个基因组成。因为这个数字是由两个小组独立得出的，许多科学家认为这个数字是可信的。但是，大多数科学家对这个相对较少的基因数量感到非常惊讶；相比之下，它只是果蝇基因数量的两倍左右。然而，对两个小组的研究结果进行更为仔细的检查表明，这两个小组均发现的基因数量大约为 17000 个（也就是说，有 17000 个相同的基因被这两个小组发现了）。因此，根据我们之前的估计量，我们会估计基因的实际数量不是 33000个，而是 $\frac{n_1 n_2}{n_{1,2}} = \frac{33000 \times 33000}{17000} \approx 64000$ 个。

对于声称发现的基因中的某些基因是否真的存在会有一些争议，因此，64000个基因应该被视为基因实际数量的上限。

**当有 $m(m \gt 2)$ 个编辑时，则上述采用的两位编辑的估计方法将不再适用。**

当 $m \gt 2$ 时，对于第 $i$ 为编辑，我们令 $\hat{p}_i$ 为由至少一位其他编辑 $j(j \ne i)$ 发现的错误中 $i$ 也发现的错误的占比，然后让 $\hat{p}_i$ 等于 $\frac{n_i}{N}$，那么 $N$ 的估计值，即 $\frac{n_i}{\hat{p}_i}$，将因不同的 $i$ 而异。

此外，使用这种方法时，即使第 $i$ 位编辑找到的错误比第 $j$ 位编辑的少，我们也有可能得到 $\hat{p}_i > \hat{p}_j$。例如，对于 $m = 3$，假设第 1 位编辑和第 2 位编辑找到了完全相同的 10 个错误，而第 3 位编辑找到了 20 个错误且只有 1 个与其他编辑找到的错误是相同的。因为第 1 位编辑和第 2 位编辑都找到了 29 个错误中的 10 个（第 2 位编辑和第 3 位编辑总共找到了 29 个不同的错误），所以，$\hat{p}_i = \frac{10}{29}$，$i = 1, 2$。另一方面，因为第 3 位编辑仅找到了其他编辑找到的 10 个错误（第 1 位编辑和第 2 为编辑找到的 10 个错误是相同的）中的 1 个，因此 $\hat{p}_3 = \frac{1}{10}$。因此，尽管第 3 位编辑找到的错误是 第 1 位编辑的两倍，但 $p_3$ 的估计值小于 $p_1$ 的估计值。

为了获得更合理的估计，我们可以将上述 $\hat{p}_i,\ i=1, ..., m$ 值作为 $p_i$ 的初步估计值。现在，令 $n_f$ 为至少由一位编辑发现的错误的数量。因为至少一位编辑发现的错误的占比为 $\frac{n_f}{N}$，因此 $\frac{n_f}{N}$ 近似等于某个错误至少被一位编辑发现的概率 $1 - \Pi_{i=1}^{m}{(1 - p_i)}$。因此，有：

$\frac{n_f}{N} \approx 1 - \Pi_{i=1}^{m}{(1-p_i)}$

假设 $N \approx \hat{N}$，有：

$$
\hat{N} = \frac{n_f}{1 - \Pi_{i=1}^{m}{(1-\hat{p_i})}}
$$ {#eq-7_2_1}

有了 $N$ 的估计，我们可以通过 $N$ 的估计来重新估计 $p_i$：

$$
\hat{p_i} = \frac{n_i}{\hat{N}}, \quad i = 1, ..., m
$$ {#eq-7_2_2}

然后，我们可以根据新的 $\hat{p_i}$ 并利用 @eq-7_2_1 重新估计 $N$。注意，估计的过程不应该就此停止，每当我们获得了 $N$ 的新估计 $\hat{N}$ 时，我们可以利用 @eq-7_2_2 获得 $p_i$ 的新估计，然后可以使用 $p_i$ 的新估计来获得 $N$ 的新估计，依此类推。）     $\blacksquare$
:::

::: {#exr-7_2_c}
**泊松分布参数的最大似然估计**。假设 $X_1, ..., X_n$ 是独立的泊松随机变量，其均值为 $\lambda$。确定 $\lambda$ 的最大似然估计量。
:::

::: {#sol-7_2_c}
$\lambda$ 的似然函数为：

$\begin{align} f(x_1, ..., x_n | \lambda) &= \frac{\lambda^{x_1}e^{-\lambda}}{x_1!} \cdots \frac{\lambda^{x_n}e^{-\lambda}}{x_n!} \\ &= \frac{\lambda^{\sum_{i=1}^{n}{x_i}}e^{-n\lambda}}{x_1! \cdots x_n!} \end{align}$

对上式取对数有：

$\textup{log}\ f(x_1, ..., x_n | \lambda) = -n\lambda + \sum_{i=1}^{n}{x_i} \textup{log}\ \lambda - \textup{log}\ c$

其中，$c = \Pi_{i=1}^{n}{x_i!}$，对上式求导有：

$\frac{d}{d\lambda} \textup{log}\ f(x_1, ..., x_n | \lambda) = -n + \frac{1}{\lambda} \sum_{i=1}^{n}{x_i}$

令上式为 0，得到最大似然估计 $\hat{\lambda} = \frac{\sum_{i=1}^{n}{x_i}}{n}$

因此，最大似然估计量为：

$d(X_1, ..., X_n) = \frac{\sum_{i=1}^{n}{x_i}}{n}$

例如，假设任何一天进入某个零售店的人数是一个泊松随机变量，其均值 $\lambda$ 未知，我们希望估计 $\lambda$ 的值。如果 20 天后，共有857 人进入该机构，那么 $\lambda$ 的最大似然估计为 $\frac{857}{20}=42.85$。也就是说，平均而言，我们估计在给定的一天将有 42.85 名顾客进入该零售店。$\blacksquare$
:::

::: {#exr-7_2_d}
1998 年加州伯克利市在 10 个随机选择的非雨天发生的交通事故数量如下：

4,0,6,5,2,1,2,0,4,3

使用这些数据来估计非雨天最多发生 2 起交通事故的天数占比。
:::

::: {#sol-7_2_d}
由于有大量司机，并且每个司机在某一天发生事故的可能性很小，因此假设每天的交通事故数量是泊松随机变量似乎是合理的。因为 $\overline{X} = \frac{1}{10} \sum_{i=1}^{10}{X_i} = 2.7$，因此，泊松分布的均值的最大似然估计值为 2.7。最多发生 2 起事故的非雨天的长期占比等于 $P\{X \le 2\}$，其中 $X$ 表示一天中的事故数。因此待计算的估计值为：

$\begin{align} P\{X \le 2\} &= P\{X = 0\} + P\{X = 1\} + P\{X = 2\} \\ &= e^{-2.7}(1 + 2.7 + \frac{{2.7}^2}{2}) \\ &= 0.4936 \end{align}$

也就是说，我们估计有不到一半的非雨天最多发生 2 起事故。$\blacksquare$
:::

::: {#exr-7_2_e}
**正态分布总体的最大似然估计**。假设 $X_1, ..., X_n$ 是相互独立的正态分布随机变量，其均值 $\mu$ 和标准差 $\sigma$ 均未知。计算其均值和标准差的最大似然估计。
:::

::: {#sol-7_2_e}
其联合概率密度函数为：

$\begin{align} f(x_1, ..., x_n | \mu, \sigma) &= \Pi_{i=1}^{n}{\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x_i - \mu)^2}{2\sigma^2}}} \\ &= (\frac{1}{2\pi})^{\frac{n}{2}} \frac{1}{\sigma^n} e^{\frac{-\sum_{i=1}^{n}{(x_i - \mu)^2}}{2\sigma^2}} \end{align}$

取对数有：

$\textup{log}\ f(x_1, ..., x_n | \mu, \sigma) = - \frac{n}{2} \textup{log}\ (2\pi) - n \textup{log}\ \sigma - \frac{\sum_{i=1}^{n}{(x_i - \mu)^2}}{2 \sigma^2}$

为了找到 $\mu$ 和 $\sigma$ 以使上述值最大化，我们计算如下的偏导数：

$\frac{\partial}{\partial \mu} \textup{log}\ f(x_1, ..., x_n | \mu, \sigma) = \frac{\sum_{i=1}^{n}{(x_i - \mu)}}{\sigma^2}$

$\frac{\partial}{\partial \sigma} \textup{log}\ f(x_1, ..., x_n | \mu, \sigma) = - \frac{n}{\sigma} + \frac{\sum_{i=1}^{n}{(x_i - \mu)^2}}{\sigma^3}$

令如上的偏导数等于 0，有：

$\hat{\mu} = \frac{\sum_{i=1}^{n}{x_i}}{n}$

$\hat{\sigma} = \bigg[\frac{\sum_{i=1}^{n}{(x_i - \hat{\mu})^2}}{n}\bigg]^{\frac{1}{2}}$

因此，正态分布的均值和标准差的最大似然估计量分别为：

$$
\begin{align}
\hat{\mu} &= \overline{X} \\
\hat{\sigma} &= \bigg[\frac{\sum_{i=1}^{n}{(X_i - \overline{X})^2}}{n}\bigg]^{\frac{1}{2}}
\end{align}
$$ {#eq-7_2_3}

需要注意的是：标准差 $\sigma$ 的最大似然估计并不等同于样本标准差：

$S = \bigg[\frac{\sum_{i=1}^{n}{(X_i - \overline{X})^2}}{n - 1}\bigg]^{\frac{1}{2}}$

在 @eq-7_2_3 中，分母为 $\sqrt{n}$，而不是样本方差中的 $\sqrt{n - 1}$。然而，对于合理大小的 $n$，$\sigma$ 的这两个估计量将近似相等。$\blacksquare$
:::

::: {#exr-7_2_f}
Kolmogorov 碎裂定律（*Kolmogorov's law of fragmentation*）指出，由矿物化合物碎裂产生的大量颗粒中的单个颗粒的大小服从近似对数正态分布（*lognormal distribution*）。如果一个随机变量 $X$ 的对数 $\textup{log}\ (X)$ 服从正态分布，那么 $X$ 则具有对数正态分布。碎裂定律最初是通过实验证明的，后来由 Kolmogorov 提供了理论基础，并被应用于各种工程研究。例如，人们用碎裂定律来分析从一堆金砂中随机挑选出的颗粒的大小。碎裂定律还应用与地震断裂带的应力释放研究中（参见：Lomnitz, C., "Global Tectonics and Earthquake Risk," *Developments in Geotectonics*, Elsevier, Amsterdam, 1979）。

假设从一大堆金属砂中取出 10 粒样品，它们的长度（以毫米为单位）分别是：

2.2, 3.4, 1.6, 0.8, 2.7, 3.3, 1.6, 2.8, 2.5, 1.9

估计整个砂堆中长度在 2~3 毫米之间的砂粒的百分比。
:::

::: {#sol-7_2_f}
取这 10 个数据值的自然对数，得到转换后的数据集结果：

0.7885, 1.2238, 0.4700, -0.2231, 0.9933, 1.1939, 0.4700, 1.0296, 0.9163, 0.6419

因为如上数据的样本均值和样本标准差分别为：

$\overline{x} = 0.7504, s = 0.4351$

```{r}
x <- c(2.2, 3.4, 1.6, 0.8, 2.7, 3.3, 1.6, 2.8, 2.5, 1.9)
log_x <- log(x)
mean_log_x <- mean(log_x)
sd_log_x <- sd(log_x)
print(mean_log_x)
print(sd_log_x)
```

因此，随机选择的砂粒长度的对数服从均值为 0.7504、标准差为 0.4351 正态分布。所以，如果 $X$ 是砂粒的长度，那么

$\begin{align} P\{2 \lt X \lt 3\} &= P\{\textup{log}\ 2 \lt \textup{log}\ X \lt \textup{log}\ 3\} \\ &= P\bigg\{\frac{\textup{log}\ 2 - 0.7504}{0.4351} \lt \frac{\textup{log}\ X - 0.7504}{0.4351} \lt \frac{\textup{log}\ 3 - 0.7504}{0.4351}\bigg\} \\ & \approx pnorm(\textup{log}\ 3 - 0.7504 / 0.4351) - pnorm(\textup{log}\ 2 - 0.7504 / 0.4351) \\ &= 0.3405766 \end{align}$

```{r}
pnorm((log(3) - 0.7504) / 0.4351) - pnorm((log(2) - 0.7504) / 0.4351)
```

$\blacksquare$
:::

当随机变量可以看作大量独立、同分布的随机变量的乘积的情况下，我们可以假设该随机变量服从对数正态分布。例如，在金融领域，经常用对数正态分布来估计股价在未来某段时间的价格分布。为了理解这种假设的合理性，我们假设当前股价是 $s$，我们关心的是经过时间 $t$ 后的股票价格 $S(t)$。对于一个较大的 $n$ 值，令 $t_i = \frac{t}{n}$，并令 $S(t_1), S(t_2), ..., S(t_n)$ 表示在时间 $t_1, t_2, ..., t_n$ 时的股价。金融领域中的一个比较常见的假设是：$\frac{S(t_i)}{S(t_{i-1})}$ 近似符合独立同分布。因此，如果我们令 $X_i = \frac{S(t_i)}{S(t_{i-1})}$，则：

$\begin{align} S(t) = S(t_n) &= S(t_0) \cdot \frac{S(t_1)}{S(t_0)} \cdot \frac{S(t_2)}{S(t_1)} \cdot \cdots \cdot \frac{S(t_n)}{S(t_{n-1})} \\ &= s \prod_{i=1}^{n} X_i \end{align}$

对上式取对数得：

$\log(S(t)) = \log(s) + \sum_{i=1}^{n} \log(X_i)$

根据中心极限定理有：$\log(S(t))$ 将近似服从正态分布。

已经证明，对于某些随机变量而言，对数正态分布是一个很好的拟合，例如病人的住院时长和车辆的行驶时间。

::: {.callout-tip}
在上述所有例子中，总体均值的最大似然估计都是样本均值 $\overline{X}$。但是并非所有情况都是如此，例如 @exm-7_2_g。
:::

::: {#exm-7_2_g}
**均匀分布的均值的最大似然估计**。假设 $X_1, ..., Xn$ 是来自均匀分布 $(0, \theta)$ 的样本，其中 $\theta$ 未知。因此，$X_i$ 的联合密度函数为：

$f(x_1, x_2, ..., x_n | \theta) = \begin{cases} \frac{1}{\theta^n}, \quad & 0 \lt x_i \lt \theta \\ 0, \quad & 其它 \end{cases}$

如果 $\theta$ 尽可能小，则 $f(x_1, x_2, ..., x_n | \theta)$ 则会尽可能的大。由于 $\theta$ 必须至少与所有观测值 $x_i$ 一样大，因此 $\theta$ 的最小的可能值等于 $max(x_1, x_2, ..., x_n)$。因此，$\theta$ 的最大似然估计量是

$\hat{\theta} = max(X_1, X_2, ..., X_n)$

因此，可以得出均匀分布均值 $\frac{\theta}{2}$ 的最大似然估计量为 $\frac{max(X_1, X_2, ..., X_n)}{2}$。$\blacksquare$
:::

### 估计寿命分布
从今天出生的孩子中随机选择一个样本，令 $X$ 表示样本中的孩子死亡时的年龄。若新生儿在其第 $i$ 年死亡，则 $X = i$，$i \geq 1$。为了估计 $X$ 的概率质量函数，令 $\lambda_i$ 表示一个新生儿在度过其第 $i - 1$ 年后在第 $i$ 年死亡的概率。即，

$\lambda_i = P\{X = i | X > i - 1\} = \frac{P\{X = i\}}{P\{X > i - 1\}}$

另外，令

$s_i = 1 - \lambda_i = \frac{P\{X > i\}}{P\{X > i - 1\}}$

表示新生儿在度过其前 $i - 1$ 年后在第 $i$ 年仍然健在的概率。我们称 $\lambda_i$ 为故障率（*failure rate*），称 $s_i$ 为生存率（*survival rate*）（个体在第 $i$ 年的生存概率）。现在，

$s_1 s_2 \cdots s_i = P\{X > 1\} \frac{P\{X > 2\}}{P\{X > 1\}} \frac{P\{X > 3\}}{P\{X > 2\}} \cdots \frac{P\{X > i\}}{P\{X > i - 1\}} = P\{X > i\}$

因此，

$P\{X = n\} = P\{X > n - 1\} \lambda_n = s_1 \cdots s_{n - 1} (1 - s_n)$

因此，我们可以通过估计 $s_i, i = 1, \ldots, n$ 来估计 $X$ 的概率质量函数。$s_i$ 可以通过查看所有在第 $i-1$ 年健在的人在第 $i$ 年仍然健在的人来估计 $s_i$ 的值，其估计值 $\hat{s}_i$ 为他们今天仍然健在的比例。然后我们将使用 $\hat{s}_1 \hat{s}_2 \cdots \hat{s}_{n - 1} (1 - \hat{s}_n)$ 来估计 $P\{X = n\}$。（注意，尽管我们在估计 $s_i$ 时使用了尽可能最新的数据，但我们对新生儿寿命的概率质量函数的估计是假设新生儿在达到年龄 $i$ 时的生存率与去年同年龄 $i$ 的人的生存率相同。）

在健康研究中，使用生存率来估计寿命分布也是很重要的，尤其是在信息不完全的情况下。例如，考虑一项研究，其中一种新药物被给与 12 名肺癌患者。假设一段时间后，我们得到了从开始服用新药到患者死亡的月份数：

$4, 7^*, 9, 11^*, 12, 3, 14^*, 1, 8, 7, 5, 3^*$

其中 $x$ 表示患者在开始复用新药后的第 $x$ 个月死亡，而 $x^*$ 表示患者服药 $x$ 个月并且仍然健在。

令 $X$ 表示开始复用新药后的生存月份数，并令

$s_i = P(X > i \mid X > i - 1) = \frac{P(X > i)}{P(X > i - 1)}$

为了估计 $s_i$，即在第 $i - 1$ 个月存活的患者也将在第 $i$ 个月存活的概率，我们应该取那些在第 $i$ 个月开始服药并且在这个月存活的患者的比例。例如，因为 12 名患者中有 1 名在第 1 个月后死亡，所以 $\hat{s}_1 = \frac{11}{12}$。因为所有在第 2 个月开始服药的 11 名患者都存活，所以 $\hat{s}_2 = \frac{11}{11}$。因为 11 名患者中有 1 名在第 3 个月后死亡，所以 $\hat{s}_3 = \frac{10}{11}$。因为 9 名患者中，有 1 名在第 4 个月后死亡，所以 $\hat{s}_4 = \frac{8}{9}$。类似的推理适用于其他月份，于是得到以下生存率估计值：

$\hat{s}_1 = \frac{11}{12}$

$\hat{s}_2 = \frac{11}{11}$

$\hat{s}_3 = \frac{10}{11}$

$\hat{s}_4 = \frac{8}{9}$

$\hat{s}_5 = \frac{7}{8}$

$\hat{s}_6 = \frac{7}{7}$

$\hat{s}_7 = \frac{6}{7}$

$\hat{s}_8 = \frac{4}{5}$

$\hat{s}_9 = \frac{3}{4}$

$\hat{s}_{10} = \frac{3}{3}$

$\hat{s}_{11} = \frac{3}{3}$

$\hat{s}_{12} = \frac{1}{2}$

$\hat{s}_{13} = \frac{1}{1}$

$\hat{s}_{14} = \frac{1}{1}$

现在，我们可以使用 $\prod_{i=1}^j \hat{s}_i$ 来估计服用新药至少存活 $j$ 个月的概率，其中 $j = 1, \ldots, 14$。例如，$P\{X > 6\}$ 的估计是 $\frac{35}{54}$。